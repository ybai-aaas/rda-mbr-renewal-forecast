{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a76b55-03c8-45fb-a6ff-0a72e6445646",
   "metadata": {},
   "source": [
    "Offline: Get cleaned dataset with quality checks from offline code\\\n",
    "Do feature engineering here - modularize\\\n",
    "Set up XGBoost model - modularize\\\n",
    "Output results to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c58127-99aa-4a93-9453-34645b6e4b5f",
   "metadata": {},
   "source": [
    "# Local only: Take a look at modeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9ce9a-b680-42f0-8646-22da91663b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import sklearn\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# model(s)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# eval metrics\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns # could not install w Python 3.13.1-could be a python version issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44476419-d02f-41d4-8cc5-69bf545fbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert f\"Pandas version: {pd.__version__}\" == \"Pandas version: 2.2.3\"\n",
    "assert f\"Sklearn version: {sklearn.__version__}\" == \"Sklearn version: 1.2.1\"\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Sklearn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6e562-cf3d-466d-a619-656d22fc4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in your S3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_objects_v2(\n",
    "    Bucket=bucket,\n",
    "    Prefix=prefix\n",
    ")\n",
    "\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print(f\"No objects found in {bucket}/{prefix}\")\n",
    "\n",
    "# !aws s3 ls s3://$bucket/sagemaker/renewal-forecast-pipeline/06132025175000/model-and-inference-data/ --no-sign-request | grep \".csv\"  # only download files that are current (not previous versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052e087-9d5c-4530-ac8a-e726a7bde5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files from S3 bucket\n",
    "!aws s3 cp s3://$bucket/sagemaker/renewal-forecast-pipeline/06132025175000/model-and-inference-data/ . --recursive --exclude \"*\" --include \"*.csv\" --exclude \"*//*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e6a65-513c-47bc-871a-5ab651bb9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_data = pd.read_csv(\"Renewal_Forecast_individual_modeling_dataset_FINAL_250613.csv\")\n",
    "inference_data = pd.read_csv(\"Renewal_Forecast_individual_inference_dataset_FINAL_250613.csv\")\n",
    "\n",
    "model_data, val_data = train_test_split(current_data, test_size=0.2, random_state=42, stratify=current_data['Renewed'])\n",
    "\n",
    "model_data.head(10)\n",
    "val_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05adb35-b4e7-4f6c-81fe-72eb2e1ba919",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566ce5e-7433-4c88-b5cc-60af7776c39d",
   "metadata": {},
   "source": [
    "# Start a Conda env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44b30f-0673-4d6d-9199-d661b837e225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !conda create -n sagemaker_renforecast_env_2026 python=3.10.6 -y\n",
    "# !conda install -n sagemaker_renforecast_env_2026 pandas==2.2.3 scikit-learn=1.2.1 numpy xgboost seaborn matplotlib category_encoders ipykernel sagemaker -y\n",
    "# !conda run -n sagemaker_renforecast_env_2026 python -m ipykernel install --user --name sagemaker_renforecast_env_2026 --display-name \"Python (sagemaker_renforecast_env_2026)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b86525-092f-4828-a95f-1b84926add34",
   "metadata": {},
   "source": [
    "After running the code above, refresh the page and select your desired kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e068a531-6392-424c-88fa-aa413b2b3ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/sagemaker_renforecast_env_2026/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bec64a-1618-411c-a8d0-3a8aae12a738",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae757da-e05e-4c5e-bca9-f27733afa391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Sagemaker session\n",
    "import sagemaker # had a corrupt installation. solved by the block below this cell\n",
    "import boto3\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat, ParameterInteger\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200e688-8df7-4c5b-8faf-a925c29b19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve corrupt installation of the sagemaker package\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"sagemaker\", \"sagemaker-core\", \"smdebug-rulesconfig\"])\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sagemaker\"])\n",
    "# Restart your kernel after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93cec647-b16f-407f-ba69-c7f610a1660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AlgorithmEstimator', 'AutoML', 'AutoMLDataChannel', 'AutoMLImageClassificationConfig', 'AutoMLInput', 'AutoMLJob', 'AutoMLJobV2', 'AutoMLTabularConfig', 'AutoMLTextClassificationConfig', 'AutoMLTextGenerationConfig', 'AutoMLTimeSeriesForecastingConfig', 'AutoMLV2', 'CandidateEstimator', 'CandidateStep', 'FactorizationMachines', 'FactorizationMachinesModel', 'FactorizationMachinesPredictor', 'FileSource', 'HyperparameterTuningJobAnalytics', 'IPInsights', 'IPInsightsModel', 'IPInsightsPredictor', 'KMeans', 'KMeansModel', 'KMeansPredictor', 'KNN', 'KNNModel', 'KNNPredictor', 'LDA', 'LDAModel', 'LDAPredictor', 'LinearLearner', 'LinearLearnerModel', 'LinearLearnerPredictor', 'LocalAutoMLDataChannel', 'LocalSession', 'MetricsSource', 'Model', 'ModelMetrics', 'ModelPackage', 'NTM', 'NTMModel', 'NTMPredictor', 'Object2Vec', 'Object2VecModel', 'PCA', 'PCAModel', 'PCAPredictor', 'PartnerAppAuthProvider', 'PipelineModel', 'Predictor', 'Processor', 'Profiler', 'ProfilerConfig', 'RandomCutForest', 'RandomCutForestModel', 'RandomCutForestPredictor', 'ScriptProcessor', 'Session', 'TrainingInput', 'TrainingJobAnalytics', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_studio', 'absolute_import', 'accept_types', 'algorithm', 'amazon', 'analytics', 'apiutils', 'async_inference', 'automl', 'base_deserializers', 'base_predictor', 'base_serializers', 'clarify', 'compute_resource_requirements', 'config', 'container_def', 'content_types', 'dataset_definition', 'debugger', 'deprecations', 'deserializers', 'drift_check_baselines', 'enums', 'environment_variables', 'estimator', 'exceptions', 'experiments', 'explainer', 'fw_utils', 'get_execution_role', 'get_model_package_args', 'git_utils', 'image_uris', 'importlib_metadata', 'inference_recommender', 'inputs', 'instance_group', 'instance_types', 'interactive_apps', 'iterators', 'job', 'jumpstart', 'lambda_helper', 'lineage', 'local', 'logs', 'metadata_properties', 'model', 'model_card', 'model_life_cycle', 'model_metrics', 'model_monitor', 'model_uris', 'network', 'parameter', 'partner_app', 'pipeline', 'pipeline_container_def', 'predictor', 'predictor_async', 'processing', 'production_variant', 'remote_function', 'resource_requirements', 's3', 's3_utils', 'script_uris', 'serializer_utils', 'serializers', 'serverless', 'session', 'session_settings', 'sklearn', 'spark', 'telemetry', 'transformer', 'tuner', 'user_agent', 'utilities', 'utils', 'vpc_utils', 'workflow']\n"
     ]
    }
   ],
   "source": [
    "print(dir(sagemaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4cad99-11af-4407-bd26-4af589911f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/sagemaker_renforecast_env_2026/lib/python3.10/site-packages/sagemaker/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(sagemaker.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42061e84-d762-419a-a452-fa9048129b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.246.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"SageMaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef4e23-92c8-4625-a144-955bd42e59b4",
   "metadata": {},
   "source": [
    "# Set up Sagemaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6639af4b-71b0-4be5-9a6f-8a0499b4fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current bucket:  sagemaker-us-east-1-922182641966\n",
      "Your current role:  arn:aws:iam::922182641966:role/service-role/SageMaker-ExecutionRole-20250328T105273\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "# dataSourceGroupName/dataSetName/ingestionTimeStamp/file.csv - this is for the RAP\n",
    "prefix = 'xgb-renewal'\n",
    "# model_artifact_prefix = 'sagemaker/renewal-forecast-pipeline/06132025175000/model-artifacts'\n",
    "print('Your current bucket: ', bucket)\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "print(\"Your current role: \", role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a782b0-6dbc-47c0-b48d-5a14927d48b4",
   "metadata": {},
   "source": [
    "# Pipeline starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9bcbc-cfe9-45c9-b076-02b5d2d0c150",
   "metadata": {},
   "source": [
    "## Step 1: Clean data and engineer features - done outside of Sagemaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab965b-0c24-42a5-8b6d-1d0ce78776ba",
   "metadata": {},
   "source": [
    "## Step 2: Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94abcc40-eb2b-4bbd-9161-6ae2f4808cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data preprocessing script (only for splitting training and validation data)\n",
    "preprocessing_script = \"\"\"\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_data(input_path, output_path, test_size=0.2, val_size=0.2, random_state=42):\n",
    "    # Preprocess data and split into train/validation/test sets\n",
    "\n",
    "    print(f\"Loading data from {input_path}\")\n",
    "\n",
    "    # Read the raw data\n",
    "    df = pd.read_csv(input_path, encoding='utf-8')\n",
    "    print(f\"Original data shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "    # Basic data info\n",
    "    print(\"Target distribution:\")\n",
    "    print(df['Renewed'].value_counts())\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    # Exclude the target column 'Renewed' from features\n",
    "    feature_columns = [col for col in df.columns if col != 'Renewed']\n",
    "\n",
    "    # Automatically identify categorical columns\n",
    "    categorical_columns = []\n",
    "    numerical_columns = []\n",
    "\n",
    "    for col in feature_columns:\n",
    "        if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            categorical_columns.append(col)\n",
    "        elif df[col].nunique() < 10 and df[col].dtype in ['int64', 'float64']:\n",
    "            # Treat low-cardinality numeric columns as categorical\n",
    "            categorical_columns.append(col)\n",
    "        else:\n",
    "            numerical_columns.append(col)\n",
    "\n",
    "    print(f\"Categorical columns ({len(categorical_columns)}): {categorical_columns}\")\n",
    "    print(f\"Numerical columns ({len(numerical_columns)}): {numerical_columns}\")\n",
    "\n",
    "    # Handle missing values\n",
    "    print(\"Missing values per column:\")\n",
    "    missing_counts = df.isnull().sum()\n",
    "    print(missing_counts[missing_counts > 0])\n",
    "\n",
    "    # Fill missing values\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Fill categorical missing values with 'Unknown'\n",
    "    for col in categorical_columns:\n",
    "        if df_processed[col].isnull().sum() > 0:\n",
    "            df_processed[col] = df_processed[col].fillna('Unknown')\n",
    "            print(f\"Filled {col} missing values with 'Unknown'\")\n",
    "\n",
    "    # Fill numerical missing values with median\n",
    "    for col in numerical_columns:\n",
    "        if df_processed[col].isnull().sum() > 0:\n",
    "            median_value = df_processed[col].median()\n",
    "            df_processed[col] = df_processed[col].fillna(median_value)\n",
    "            print(f\"Filled {col} missing values with median: {median_value}\")\n",
    "\n",
    "    # Convert categorical columns to string type for consistency\n",
    "    for col in categorical_columns:\n",
    "        df_processed[col] = df_processed[col].astype(str)\n",
    "\n",
    "    # Split data into train/temp, then temp into validation/test\n",
    "    X = df_processed[feature_columns]\n",
    "    y = df_processed['Renewed']\n",
    "\n",
    "    # First split: train vs (validation + test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=(test_size + val_size), random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Second split: validation vs test\n",
    "    relative_test_size = test_size / (test_size + val_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=relative_test_size, random_state=random_state, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    print(f\"Data split:\")\n",
    "    print(f\"Train: {X_train.shape[0]} samples\")\n",
    "    print(f\"Validation: {X_val.shape[0]} samples\")\n",
    "    print(f\"Test: {X_test.shape[0]} samples\")\n",
    "\n",
    "    # Create output directories\n",
    "    train_dir = os.path.join(output_path, 'train')\n",
    "    val_dir = os.path.join(output_path, 'validation')\n",
    "    test_dir = os.path.join(output_path, 'test')\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Combine features and target for saving\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    val_df = pd.concat([X_val, y_val], axis=1)\n",
    "    test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    # Save datasets\n",
    "    train_df.to_csv(os.path.join(train_dir, 'train.csv'), index=False)\n",
    "    val_df.to_csv(os.path.join(val_dir, 'validation.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join(test_dir, 'test.csv'), index=False)\n",
    "\n",
    "    print(f\"Saved datasets to {output_path}\")\n",
    "\n",
    "    # Create metadata for the pipeline\n",
    "    metadata = {\n",
    "        \"feature_names\": feature_columns,\n",
    "        \"categorical_columns\": categorical_columns,\n",
    "        \"numerical_columns\": numerical_columns,\n",
    "        \"target_column\": \"Renewed\",\n",
    "        \"original_shape\": df.shape,\n",
    "        \"train_shape\": train_df.shape,\n",
    "        \"validation_shape\": val_df.shape,\n",
    "        \"test_shape\": test_df.shape,\n",
    "        \"preprocessing_info\": {\n",
    "            \"missing_value_strategy\": {\n",
    "                \"categorical\": \"Unknown\",\n",
    "                \"numerical\": \"median\"\n",
    "            },\n",
    "            \"train_test_split\": {\n",
    "                \"test_size\": test_size,\n",
    "                \"validation_size\": val_size,\n",
    "                \"random_state\": random_state\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save metadata to all directories (required by your training script)\n",
    "    for directory in [train_dir, val_dir, test_dir]:\n",
    "        with open(os.path.join(directory, 'metadata.json'), 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "\n",
    "    print(\"Metadata saved to all directories\")\n",
    "\n",
    "    return metadata\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Preprocess data for XGBoost training')\n",
    "\n",
    "    # SageMaker processing job arguments\n",
    "    parser.add_argument('--input-data', \n",
    "                        type=str, \n",
    "                        default='/opt/ml/processing/input/Renewal_Forecast_individual_modeling_dataset_FINAL_250703_v3.csv',\n",
    "                        help='Path to input data file')\n",
    "    parser.add_argument('--output-data', type=str, default='/opt/ml/processing/output',\n",
    "                        help='Path to output directory')\n",
    "    parser.add_argument('--test-size', type=float, default=0.2,\n",
    "                        help='Proportion of data to use for test set')\n",
    "    parser.add_argument('--val-size', type=float, default=0.2,\n",
    "                        help='Proportion of data to use for validation set')\n",
    "    parser.add_argument('--random-state', type=int, default=42,\n",
    "                        help='Random state for reproducibility')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(\"Starting data preprocessing...\")\n",
    "    print(f\"Input data: {args.input_data}\")\n",
    "    print(f\"Output directory: {args.output_data}\")\n",
    "    print(f\"Test size: {args.test_size}\")\n",
    "    print(f\"Validation size: {args.val_size}\")\n",
    "    print(f\"Random state: {args.random_state}\")\n",
    "    \n",
    "    # Run preprocessing\n",
    "    try:\n",
    "        metadata = preprocess_data(\n",
    "            input_path=args.input_data,\n",
    "            output_path=args.output_data,\n",
    "            test_size=args.test_size,\n",
    "            val_size=args.val_size,\n",
    "            random_state=args.random_state\n",
    "        )\n",
    "        \n",
    "        print(\"Preprocessing completed successfully!\")\n",
    "        print(f\"Features: {len(metadata['feature_names'])}\")\n",
    "        print(f\"Categorical features: {len(metadata['categorical_columns'])}\")\n",
    "        print(f\"Numerical features: {len(metadata['numerical_columns'])}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {str(e)}\")\n",
    "        raise e\n",
    "\"\"\"\n",
    "with open(\"preprocessing.py\", \"w\") as f:\n",
    "    f.write(preprocessing_script)\n",
    "\n",
    "# Create training script\n",
    "training_script = \"\"\"\n",
    "# train_xgb.py - training script with categorical handling\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def convert_categorical_columns(df, categorical_columns):\n",
    "    # Convert specified columns to categorical type for XGBoost\n",
    "    df_copy = df.copy()\n",
    "    for col in categorical_columns:\n",
    "        if col in df_copy.columns:\n",
    "            # XGBoost expects categorical columns as 'category' dtype\n",
    "            df_copy[col] = df_copy[col].astype('category')\n",
    "    return df_copy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # XGBoost hyperparameters\n",
    "    parser.add_argument(\"--num_round\", type=int, default=100)\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=6)\n",
    "    parser.add_argument(\"--eta\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--subsample\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--colsample_bytree\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--min_child_weight\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--scale_pos_weight\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--objective\", type=str, default=\"binary:logistic\")\n",
    "    parser.add_argument(\"--eval_metric\", type=str, default=\"auc\")\n",
    "    parser.add_argument(\"--enable_categorical\", type=str, default=\"true\")\n",
    "    parser.add_argument(\"--tree_method\", type=str, default=\"hist\")\n",
    "    \n",
    "    # SageMaker specific arguments\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(\"Arguments received:\")\n",
    "    for arg, value in vars(args).items():\n",
    "        print(f\"{arg}: {value}\")\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(f\"{args.train}/train.csv\", encoding='utf-8')\n",
    "    val_df = pd.read_csv(f\"{args.validation}/validation.csv\", encoding='utf-8')\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(f\"{args.train}/metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    feature_names = metadata[\"feature_names\"]\n",
    "    categorical_columns = metadata.get(\"categorical_columns\", [])\n",
    "    \n",
    "    print(f\"Feature names: {feature_names}\")\n",
    "    print(f\"Categorical columns: {categorical_columns}\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train = train_df[feature_names].copy()\n",
    "    y_train = train_df[\"Renewed\"].copy()\n",
    "    X_val = val_df[feature_names].copy()\n",
    "    y_val = val_df[\"Renewed\"].copy()\n",
    "    \n",
    "    # Convert categorical columns to proper categorical type\n",
    "    X_train = convert_categorical_columns(X_train, categorical_columns)\n",
    "    X_val = convert_categorical_columns(X_val, categorical_columns)\n",
    "    \n",
    "    print(f\"Training data shape: {X_train.shape}\")\n",
    "    print(f\"Validation data shape: {X_val.shape}\")\n",
    "    print(f\"Training target distribution:{y_train.value_counts()}\")\n",
    "    \n",
    "    # For XGBoost native container, we need to use the training API approach\n",
    "    # Create XGBClassifier for categorical support\n",
    "    enable_categorical = args.enable_categorical.lower() == \"true\"\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=args.num_round,\n",
    "        max_depth=args.max_depth,\n",
    "        learning_rate=args.eta,\n",
    "        subsample=args.subsample,\n",
    "        colsample_bytree=args.colsample_bytree,\n",
    "        min_child_weight=args.min_child_weight,\n",
    "        scale_pos_weight=args.scale_pos_weight,\n",
    "        objective=args.objective,\n",
    "        eval_metric=args.eval_metric,\n",
    "        enable_categorical=enable_categorical,\n",
    "        tree_method=args.tree_method,\n",
    "        random_state=42,\n",
    "        verbosity=1\n",
    "    )\n",
    "    \n",
    "    print(\"Starting training with categorical support...\")\n",
    "    print(f\"Enable categorical: {enable_categorical}\")\n",
    "    print(f\"Tree method: {args.tree_method}\")\n",
    "    \n",
    "    # Train the model\n",
    "    # model.fit(\n",
    "    #     X_train, y_train,\n",
    "    #     eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    #     eval_names=['train', 'validation'],\n",
    "    #     early_stopping_rounds=10,\n",
    "    #     verbose=True\n",
    "    # )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Make predictions for validation metrics\n",
    "    val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_val, val_pred)),\n",
    "        \"precision\": float(precision_score(y_val, val_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_val, val_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_val, val_pred, zero_division=0)),\n",
    "        \"auc\": float(roc_auc_score(y_val, val_pred_proba))\n",
    "    }\n",
    "    \n",
    "    print(\"Validation Metrics:\")\n",
    "    for metric, value in val_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Save model using pickle\n",
    "    model_path = os.path.join(args.model_dir, \"model.pkl\")\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    # Also save in XGBoost native format for compatibility\n",
    "    xgb_model_path = os.path.join(args.model_dir, \"xgboost-model\")\n",
    "    model.save_model(xgb_model_path)\n",
    "    print(f\"XGBoost model saved to {xgb_model_path}\")\n",
    "    \n",
    "    # Save metadata\n",
    "    model_metadata = {\n",
    "        \"feature_names\": feature_names,\n",
    "        \"categorical_columns\": categorical_columns,\n",
    "        \"validation_metrics\": val_metrics,\n",
    "        \"model_type\": \"XGBClassifier\",\n",
    "        \"hyperparameters\": {\n",
    "            \"n_estimators\": args.num_round,\n",
    "            \"max_depth\": args.max_depth,\n",
    "            \"learning_rate\": args.eta,\n",
    "            \"enable_categorical\": enable_categorical,\n",
    "            \"tree_method\": args.tree_method\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(args.model_dir, \"model_metadata.json\"), \"w\") as f:\n",
    "        json.dump(model_metadata, f, indent=2)\n",
    "    \n",
    "    print(\"Training completed successfully!\")\n",
    "    print(f\"Best iteration: {model.best_iteration}\")\n",
    "    print(f\"Best score: {model.best_score}\") \"\"\"\n",
    "\n",
    "# Save training script\n",
    "with open(\"train.py\", \"w\") as f:\n",
    "    f.write(training_script)\n",
    "\n",
    "# Evaluation script\n",
    "evaluation_script = \"\"\"\n",
    "# evaluate.py - Model evaluation script\n",
    "# evaluate.py - Model evaluation script\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    precision_recall_curve, roc_curve\n",
    ")\n",
    "\n",
    "def convert_categorical_columns(df, categorical_columns):\n",
    "    # Convert specified columns to categorical type\n",
    "    df_copy = df.copy()\n",
    "    for col in categorical_columns:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].astype('category')\n",
    "    return df_copy\n",
    "\n",
    "def create_evaluation_plots(y_true, y_pred, y_pred_proba, output_dir):\n",
    "    # Create evaluation plots\n",
    "    \n",
    "    # 1. Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Not Renewed', 'Renewed'],\n",
    "                yticklabels=['Not Renewed', 'Renewed'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. ROC Curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    auc_score = roc_auc_score(y_true, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'roc_curve.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Precision-Recall Curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    plt.plot(recall, precision, color='blue', lw=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'precision_recall_curve.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Prediction Distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(y_pred_proba[y_true == 0], bins=30, alpha=0.7, label='Not Renewed', color='red')\n",
    "    plt.hist(y_pred_proba[y_true == 1], bins=30, alpha=0.7, label='Renewed', color='blue')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Prediction Probability Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot([y_pred_proba[y_true == 0], y_pred_proba[y_true == 1]], \n",
    "                labels=['Not Renewed', 'Renewed'])\n",
    "    plt.ylabel('Predicted Probability')\n",
    "    plt.title('Probability Distribution by Class')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'prediction_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting model evaluation...\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    test_df = pd.read_csv(test_path, encoding='utf-8')\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(\"/opt/ml/processing/test/metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    feature_names = metadata[\"feature_names\"]\n",
    "    categorical_columns = metadata.get(\"categorical_columns\", [])\n",
    "    \n",
    "    print(f\"Test data shape: {test_df.shape}\")\n",
    "    print(f\"Feature names: {feature_names}\")\n",
    "    print(f\"Categorical columns: {categorical_columns}\")\n",
    "    \n",
    "    # Prepare test data\n",
    "    X_test = test_df[feature_names]\n",
    "    y_test = test_df[\"Renewed\"]\n",
    "    \n",
    "    # Convert categorical columns\n",
    "    X_test = convert_categorical_columns(X_test, categorical_columns)\n",
    "    \n",
    "    # Load model - try pickled XGBClassifier first, then XGBoost native\n",
    "    model_pkl_path = \"/opt/ml/processing/model/model.pkl\"\n",
    "    model_xgb_path = \"/opt/ml/processing/model/xgboost-model\"\n",
    "    \n",
    "    if os.path.exists(model_pkl_path):\n",
    "        print(\"Loading pickled XGBClassifier model...\")\n",
    "        import pickle\n",
    "        with open(model_pkl_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        model_type = \"XGBClassifier\"\n",
    "    elif os.path.exists(model_xgb_path):\n",
    "        print(\"Loading XGBoost native model...\")\n",
    "        import xgboost as xgb\n",
    "        model = xgb.Booster()\n",
    "        model.load_model(model_xgb_path)\n",
    "        model_type = \"Booster\"\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No model file found\")\n",
    "    \n",
    "    print(f\"Model type: {model_type}\")\n",
    "    print(\"Making predictions...\")\n",
    "    \n",
    "    # Make predictions based on model type\n",
    "    if model_type == \"XGBClassifier\":\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        # XGBoost Booster\n",
    "        dtest = xgb.DMatrix(X_test, enable_categorical=True)\n",
    "        y_pred_proba = model.predict(dtest)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"binary_classification_metrics\": {\n",
    "            \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "            \"precision\": float(precision_score(y_test, y_pred)),\n",
    "            \"recall\": float(recall_score(y_test, y_pred)),\n",
    "            \"f1\": float(f1_score(y_test, y_pred)),\n",
    "            \"roc_auc\": float(roc_auc_score(y_test, y_pred_proba))\n",
    "        },\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist(),\n",
    "        \"classification_report\": classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "    \n",
    "    print(\"Evaluation Metrics:\")\n",
    "    for metric, value in metrics[\"binary_classification_metrics\"].items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save metrics\n",
    "    with open(os.path.join(output_dir, \"evaluation.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    # Create evaluation plots\n",
    "    create_evaluation_plots(y_test, y_pred, y_pred_proba, output_dir)\n",
    "    \n",
    "    # Feature importance\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # XGBClassifier\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "    elif hasattr(model, 'get_score'):\n",
    "        # XGBoost Booster\n",
    "        importance_dict = model.get_score(importance_type='gain')\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': list(importance_dict.keys()),\n",
    "            'Importance': list(importance_dict.values())\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "    else:\n",
    "        importance_df = None\n",
    "    \n",
    "    if importance_df is not None:\n",
    "        # Save feature importance\n",
    "        importance_df.to_csv(os.path.join(output_dir, \"feature_importance.csv\"), index=False)\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = importance_df.head(20)\n",
    "        plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title('Top 20 Feature Importances')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'feature_importance.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # Save detailed predictions for analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'actual': y_test,\n",
    "        'predicted': y_pred,\n",
    "        'probability': y_pred_proba\n",
    "    })\n",
    "    results_df.to_csv(os.path.join(output_dir, \"predictions.csv\"), index=False)\n",
    "    \n",
    "    print(f\"Evaluation completed. Results saved to {output_dir}\")\n",
    "    print(f\"Final F1 Score: {metrics['binary_classification_metrics']['f1']:.4f}\")\n",
    "    print(f\"Final AUC Score: {metrics['binary_classification_metrics']['roc_auc']:.4f}\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Save evaluation script\n",
    "with open(\"evaluate.py\", \"w\") as f:\n",
    "    f.write(evaluation_script)\n",
    "\n",
    "# Create inference script\n",
    "inference_script = \"\"\"\n",
    "# inference.py - Inference script for batch transform with categorical support\n",
    "# inference.py - Inference script for XGBoost native container\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from io import StringIO\n",
    "\n",
    "def convert_categorical_columns(df, categorical_columns):\n",
    "    # Convert specified columns to categorical type\n",
    "    df_copy = df.copy()\n",
    "    for col in categorical_columns:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].astype('category')\n",
    "    return df_copy\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # Load model for SageMaker XGBoost container. SageMaker will call this function to load the model.\n",
    "\n",
    "    print(f\"Loading model from {model_dir}\")\n",
    "    \n",
    "    # Try to load the pickled XGBClassifier first (for categorical support)\n",
    "    model_path = os.path.join(model_dir, \"model.pkl\")\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Loading pickled XGBClassifier model...\")\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    else:\n",
    "        # Fallback to XGBoost native format\n",
    "        print(\"Loading XGBoost native model...\")\n",
    "        xgb_model_path = os.path.join(model_dir, \"xgboost-model\")\n",
    "        model = xgb.Booster()\n",
    "        model.load_model(xgb_model_path)\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata_path = os.path.join(model_dir, \"model_metadata.json\")\n",
    "    with open(metadata_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"feature_names\": metadata[\"feature_names\"],\n",
    "        \"categorical_columns\": metadata.get(\"categorical_columns\", []),\n",
    "        \"model_type\": metadata.get(\"model_type\", \"XGBClassifier\")\n",
    "    }\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    # Parse input data for prediction. SageMaker will call this function to process the input.\n",
    "    \n",
    "    print(f\"Processing input with content type: {request_content_type}\")\n",
    "    \n",
    "    if request_content_type == \"text/csv\":\n",
    "        # For batch transform, input comes as CSV string\n",
    "        df = pd.read_csv(StringIO(request_body), encoding='utf-8')\n",
    "        print(f\"Loaded CSV data with shape: {df.shape}\")\n",
    "        return df\n",
    "    elif request_content_type == \"application/json\":\n",
    "        # For real-time inference\n",
    "        data = json.loads(request_body)\n",
    "        if isinstance(data, dict):\n",
    "            df = pd.DataFrame([data])\n",
    "        elif isinstance(data, list):\n",
    "            df = pd.DataFrame(data)\n",
    "        else:\n",
    "            raise ValueError(\"JSON data must be dict or list of dicts\")\n",
    "        print(f\"Loaded JSON data with shape: {df.shape}\")\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "\n",
    "def predict_fn(input_data, model_components):\n",
    "    # Make predictions using the loaded model. SageMaker will call this function to make predictions.\n",
    "    \n",
    "    model = model_components[\"model\"]\n",
    "    feature_names = model_components[\"feature_names\"]\n",
    "    categorical_columns = model_components[\"categorical_columns\"]\n",
    "    model_type = model_components[\"model_type\"]\n",
    "    \n",
    "    print(f\"Making predictions with model type: {model_type}\")\n",
    "    print(f\"Input data shape: {input_data.shape}\")\n",
    "    print(f\"Expected features: {len(feature_names)}\")\n",
    "    print(f\"Categorical columns: {len(categorical_columns)}\")\n",
    "    \n",
    "    # Ensure we have all required features\n",
    "    missing_features = set(feature_names) - set(input_data.columns)\n",
    "    if missing_features:\n",
    "        print(f\"Warning: Missing features {missing_features}, filling with defaults\")\n",
    "        for feature in missing_features:\n",
    "            if feature in categorical_columns:\n",
    "                input_data[feature] = 'Unknown'  # Default for categorical\n",
    "            else:\n",
    "                input_data[feature] = 0  # Default for numerical\n",
    "    \n",
    "    # Select and order features\n",
    "    X = input_data[feature_names].copy()\n",
    "    \n",
    "    # Convert categorical columns\n",
    "    X = convert_categorical_columns(X, categorical_columns)\n",
    "    \n",
    "    print(f\"Data prepared for prediction, shape: {X.shape}\")\n",
    "    \n",
    "    # Make predictions based on model type\n",
    "    if model_type == \"XGBClassifier\" and hasattr(model, 'predict_proba'):\n",
    "        # Using XGBClassifier with categorical support\n",
    "        predictions = model.predict(X)\n",
    "        probabilities = model.predict_proba(X)[:, 1]\n",
    "    else:\n",
    "        # Using XGBoost Booster (native format)\n",
    "        dmatrix = xgb.DMatrix(X, enable_categorical=True)\n",
    "        probabilities = model.predict(dmatrix)\n",
    "        predictions = (probabilities > 0.5).astype(int)\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": predictions.tolist(),\n",
    "        \"probabilities\": probabilities.tolist()\n",
    "    }\n",
    "\n",
    "def output_fn(prediction, response_content_type):\n",
    "    # Format the prediction output. SageMaker will call this function to format the response.\n",
    "\n",
    "    print(f\"Formatting output with content type: {response_content_type}\")\n",
    "    \n",
    "    if response_content_type == \"application/json\":\n",
    "        return json.dumps(prediction)\n",
    "    elif response_content_type == \"text/csv\":\n",
    "        # For batch transform, return CSV format\n",
    "        df = pd.DataFrame({\n",
    "            'prediction': prediction['predictions'],\n",
    "            'probability': prediction['probabilities']\n",
    "        })\n",
    "        return df.to_csv(index=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported response content type: {response_content_type}\")\n",
    "\"\"\"\n",
    "\n",
    "# Save inference script\n",
    "with open(\"inference.py\", \"w\") as f:\n",
    "    f.write(inference_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "525f87fc-4efe-4022-bed1-7f595bee9540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-922182641966/xgb-renewal/scripts/inference.py'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload scripts to S3\n",
    "# need a script to load dataset into session\n",
    "# session.upload_data(path=..., bucket=bucket, key_prefix=f\"{prefix}/scripts\")\n",
    "session.upload_data(path=\"preprocessing.py\", bucket=bucket, key_prefix=f\"{prefix}/scripts\")\n",
    "session.upload_data(path=\"train.py\", bucket=bucket, key_prefix=f\"{prefix}/scripts\")\n",
    "session.upload_data(path=\"evaluate.py\", bucket=bucket, key_prefix=f\"{prefix}/scripts\")\n",
    "session.upload_data(path=\"inference.py\", bucket=bucket, key_prefix=f\"{prefix}/scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86269572-da46-478f-a029-294a1ddc5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker_pipeline.py - Complete XGBoost pipeline for renewal prediction\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.xgboost import XGBoost\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat, ParameterInteger\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "import os\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "pipeline_session = PipelineSession()\n",
    "# bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# Define pipeline parameters\n",
    "input_data_uri = ParameterString(\n",
    "    name=\"InputDataUri\",\n",
    "    default_value=f\"s3://{bucket}/xgb-renewal/data/Renewal_Forecast_individual_modeling_dataset_FINAL_250703_v3.csv\"\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "# XGBoost hyperparameters\n",
    "num_round = ParameterInteger(name=\"NumRound\", default_value=500)\n",
    "max_depth = ParameterInteger(name=\"MaxDepth\", default_value=7)\n",
    "eta = ParameterFloat(name=\"Eta\", default_value=0.01)\n",
    "subsample = ParameterFloat(name=\"Subsample\", default_value=0.8)\n",
    "colsample_bytree = ParameterFloat(name=\"ColsampleByTree\", default_value=0.8)\n",
    "\n",
    "def create_preprocessing_step():\n",
    "    \"\"\"Create preprocessing step using SKLearn processor\"\"\"\n",
    "    \n",
    "    # Create SKLearn processor for preprocessing\n",
    "    sklearn_processor = SKLearnProcessor(\n",
    "        framework_version='0.23-1',\n",
    "        role=role,\n",
    "        instance_type='ml.m5.large',\n",
    "        instance_count=1,\n",
    "        sagemaker_session=pipeline_session\n",
    "    )\n",
    "    \n",
    "    # Define preprocessing step\n",
    "    preprocessing_step = ProcessingStep(\n",
    "        name=\"PreprocessingStep\",\n",
    "        processor=sklearn_processor,\n",
    "        code=\"preprocessing.py\",\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=input_data_uri,\n",
    "                destination=\"/opt/ml/processing/input\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train\",\n",
    "                source=\"/opt/ml/processing/output/train\",\n",
    "                destination=f\"s3://{bucket}/renewal-prediction/processed-data/train\"\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"validation\",\n",
    "                source=\"/opt/ml/processing/output/validation\",\n",
    "                destination=f\"s3://{bucket}/renewal-prediction/processed-data/validation\"\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test\",\n",
    "                source=\"/opt/ml/processing/output/test\",\n",
    "                destination=f\"s3://{bucket}/renewal-prediction/processed-data/test\"\n",
    "            )\n",
    "        ],\n",
    "        job_arguments=[\n",
    "            \"--input-data\", \"/opt/ml/processing/input/Renewal_Forecast_individual_modeling_dataset_FINAL_250703_v3.csv\",\n",
    "            \"--output-data\", \"/opt/ml/processing/output\",\n",
    "            \"--test-size\", \"0.2\",\n",
    "            \"--val-size\", \"0.2\",\n",
    "            \"--random-state\", \"42\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return preprocessing_step\n",
    "\n",
    "def create_training_step(preprocessing_step):\n",
    "    \"\"\"Create XGBoost training step\"\"\"\n",
    "    \n",
    "    # XGBoost estimator with categorical support\n",
    "    xgb_estimator = XGBoost(\n",
    "        entry_point=\"train.py\",\n",
    "        framework_version=\"1.5-1\",\n",
    "        py_version=\"py3\",\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        instance_count=1,\n",
    "        role=role,\n",
    "        sagemaker_session=pipeline_session,\n",
    "        hyperparameters={\n",
    "            \"num_round\": num_round,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"eta\": eta,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"enable_categorical\": \"true\",\n",
    "            \"tree_method\": \"hist\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Training step\n",
    "    training_step = TrainingStep(\n",
    "        name=\"TrainingStep\",\n",
    "        estimator=xgb_estimator,\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\"\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return training_step\n",
    "\n",
    "def create_evaluation_step(training_step, preprocessing_step):\n",
    "    \"\"\"Create model evaluation step\"\"\"\n",
    "    \n",
    "    # Create processor for evaluation\n",
    "    evaluation_processor = SKLearnProcessor(\n",
    "        framework_version='0.23-1',\n",
    "        role=role,\n",
    "        instance_type='ml.m5.large',\n",
    "        instance_count=1,\n",
    "        sagemaker_session=pipeline_session\n",
    "    )\n",
    "    \n",
    "    # Evaluation step\n",
    "    evaluation_step = ProcessingStep(\n",
    "        name=\"EvaluationStep\",\n",
    "        processor=evaluation_processor,\n",
    "        code=\"evaluate.py\",\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination=\"/opt/ml/processing/model\"\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"evaluation\",\n",
    "                source=\"/opt/ml/processing/evaluation\",\n",
    "                destination=f\"s3://{bucket}/renewal-prediction/evaluation\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return evaluation_step\n",
    "\n",
    "def create_model_registration_step(training_step, evaluation_step):\n",
    "    \"\"\"Create model registration step\"\"\"\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(\n",
    "        image_uri=training_step.properties.AlgorithmSpecification.TrainingImage,\n",
    "        model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        sagemaker_session=pipeline_session,\n",
    "        role=role,\n",
    "        entry_point=\"inference.py\",\n",
    "        source_dir=\".\"\n",
    "    )\n",
    "    \n",
    "    # Model metrics\n",
    "    model_metrics = ModelMetrics(\n",
    "        model_statistics=MetricsSource(\n",
    "            s3_uri=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    evaluation_step.properties.ProcessingOutputConfig.Outputs['evaluation'].S3Output.S3Uri,\n",
    "                    \"evaluation.json\"\n",
    "                ]\n",
    "                    ),\n",
    "            content_type=\"application/json\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Register model step\n",
    "    register_model_step = RegisterModel(\n",
    "        name=\"RegisterModelStep\",\n",
    "        estimator=training_step.estimator,\n",
    "        model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        content_types=[\"text/csv\", \"application/json\"],\n",
    "        response_types=[\"text/csv\", \"application/json\"],\n",
    "        inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        model_package_group_name=\"renewal-prediction-model-group\",\n",
    "        approval_status=model_approval_status,\n",
    "        model_metrics=model_metrics\n",
    "    )\n",
    "    \n",
    "    return register_model_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7995b6ff-b9e4-4bee-ac5c-b622260e7cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " preprocessing.py exists\n",
      " train.py exists\n",
      " evaluate.py exists\n",
      " inference.py exists\n",
      " s3://sagemaker-us-east-1-922182641966/xgb-renewal/data/Renewal_Forecast_individual_modeling_dataset_FINAL_250703_v2.csv FOUND!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure everything exists before starting pipeline\n",
    "required_files = ['preprocessing.py', 'train.py', 'evaluate.py', 'inference.py']\n",
    "\n",
    "for file in required_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\" {file} exists\")\n",
    "    else:\n",
    "        print(f\" {file} is missing!\")\n",
    "\n",
    "# Check if input data exists\n",
    "import boto3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def check_s3_file(s3_uri):\n",
    "    try:\n",
    "        # Parse S3 URI\n",
    "        bucket = s3_uri.split('/')[2]\n",
    "        key = '/'.join(s3_uri.split('/')[3:])\n",
    "        \n",
    "        # Check if file exists\n",
    "        s3_client.head_object(Bucket=bucket, Key=key)\n",
    "        print(f\" {s3_uri} FOUND!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\" {s3_uri} not found: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check your input data\n",
    "bucket = bucket\n",
    "input_data = f\"s3://{bucket}/xgb-renewal/data/Renewal_Forecast_individual_modeling_dataset_FINAL_250703_v2.csv\"\n",
    "check_s3_file(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d64de53a-a343-494c-897a-6e95870ed736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.large.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ARN: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline\n",
      "Pipeline execution started: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/0w0mlib8ala1\n",
      "Monitor the pipeline in SageMaker Studio or AWS Console\n"
     ]
    }
   ],
   "source": [
    "def create_pipeline():\n",
    "    \"\"\"Create and return the complete pipeline\"\"\"\n",
    "    \n",
    "    # Create pipeline steps\n",
    "    preprocessing_step = create_preprocessing_step()\n",
    "    training_step = create_training_step(preprocessing_step)\n",
    "    evaluation_step = create_evaluation_step(training_step, preprocessing_step)\n",
    "    register_model_step = create_model_registration_step(training_step, evaluation_step)\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(\n",
    "        name=\"RenewalForecastPipeline\",\n",
    "        parameters=[\n",
    "            input_data_uri,\n",
    "            model_approval_status,\n",
    "            num_round,\n",
    "            max_depth,\n",
    "            eta,\n",
    "            subsample,\n",
    "            colsample_bytree\n",
    "        ],\n",
    "        steps=[\n",
    "            preprocessing_step,\n",
    "            training_step,\n",
    "            evaluation_step,\n",
    "            register_model_step\n",
    "        ],\n",
    "        sagemaker_session=pipeline_session\n",
    "    )\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create and upload pipeline\n",
    "    pipeline = create_pipeline()\n",
    "    \n",
    "    # Create or update pipeline\n",
    "    response = pipeline.upsert(role_arn=role)\n",
    "    \n",
    "    # print(f\"Pipeline created: {response['Name']}\")\n",
    "    print(f\"Pipeline ARN: {response['PipelineArn']}\")\n",
    "    \n",
    "    # Start pipeline execution\n",
    "    execution = pipeline.start()\n",
    "    \n",
    "    print(f\"Pipeline execution started: {execution.arn}\")\n",
    "    print(\"Monitor the pipeline in SageMaker Studio or AWS Console\")\n",
    "    \n",
    "    # Wait for completion (optional)\n",
    "    # execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0f3f767-85ed-4743-bcb6-a9874324d464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/0w0mlib8ala1\n",
      "Status: Executing\n",
      "Started: 2025-07-12 01:11:59.122000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/jtl20aepymhk\n",
      "Status: Failed\n",
      "Started: 2025-07-12 00:54:41.689000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/mcfxjsvdbfvw\n",
      "Status: Failed\n",
      "Started: 2025-07-12 00:42:20.580000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/gs7xuw3pjx3g\n",
      "Status: Failed\n",
      "Started: 2025-07-12 00:35:41.602000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/v3nbjkx2buiv\n",
      "Status: Failed\n",
      "Started: 2025-07-11 23:57:47.486000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/72yfmvmzp6a8\n",
      "Status: Failed\n",
      "Started: 2025-07-11 22:27:03.058000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/p1bag5x8nm4r\n",
      "Status: Failed\n",
      "Started: 2025-07-10 22:04:05.084000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/fwuj1a14pcmn\n",
      "Status: Failed\n",
      "Started: 2025-07-10 21:51:33.695000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/3uxbj2cqztiq\n",
      "Status: Failed\n",
      "Started: 2025-07-10 21:46:59.412000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/olsi9ryw9e9n\n",
      "Status: Failed\n",
      "Started: 2025-07-10 21:38:42.233000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/6nwfdmj8iwsl\n",
      "Status: Failed\n",
      "Started: 2025-07-10 21:24:26.312000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/0jr95horfp6a\n",
      "Status: Failed\n",
      "Started: 2025-07-10 21:16:18.226000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/6wnt1j3w6zrg\n",
      "Status: Failed\n",
      "Started: 2025-07-10 20:54:11.797000+00:00\n",
      "---\n",
      "Execution: arn:aws:sagemaker:us-east-1:922182641966:pipeline/RenewalForecastPipeline/execution/3xd0bvvuf00b\n",
      "Status: Failed\n",
      "Started: 2025-07-10 19:56:11.455000+00:00\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "sm_client = boto3.client('sagemaker')\n",
    "response = sm_client.list_pipeline_executions(\n",
    "    PipelineName=\"RenewalForecastPipeline\"\n",
    ")\n",
    "for execution in response['PipelineExecutionSummaries']:\n",
    "    # print(f\"Execution: {execution['PipelineStepName']}\")\n",
    "    print(f\"Execution: {execution['PipelineExecutionArn']}\")\n",
    "    print(f\"Status: {execution['PipelineExecutionStatus']}\")\n",
    "    print(f\"Started: {execution['StartTime']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d01f8-6027-4440-b156-1d4d299b6a7c",
   "metadata": {},
   "source": [
    "## Pipeline code - old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0472b-a895-48bb-aacc-60cce9e4c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try checking permissions\n",
    "# import boto3\n",
    "# iam = boto3.client('iam')\n",
    "# role_name = 'SageMaker-ExecutionRole-20250328T105273'\n",
    "\n",
    "# try:\n",
    "#     attached_policies = iam.list_attached_role_policies(RoleName=role_name)\n",
    "#     print(\"Attached policies:\", attached_policies)\n",
    "\n",
    "#     inline_policies = iam.list_role_policies(RoleName=role_name)\n",
    "#     print(\"Inline policies:\", inline_policies)\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Found error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1faf9-caf1-4e62-a65e-15672120c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SageMaker Pipeline for XGBoost with Categorical Support\n",
    "# # Configuration\n",
    "# region = 'us-east-1'\n",
    "# bucket = bucket\n",
    "# prefix = prefix\n",
    "# role = role\n",
    "# input_data_uri = f\"s3://{bucket}/{prefix}/data\"\n",
    "# output_data_uri = f\"s3://{bucket}/{prefix}/output\"\n",
    "# model_uri = f\"s3://{bucket}/{prefix}/model\"\n",
    "\n",
    "# session = sagemaker.Session()\n",
    "# pipeline_session = PipelineSession()\n",
    "\n",
    "# # Pipeline Parameters\n",
    "# model_approval_status = ParameterString(\n",
    "#     name=\"ModelApprovalStatus\", \n",
    "#     default_value=\"PendingManualApproval\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0f922-59fd-4c2b-a65f-cb5d4144225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Data Preprocessing\n",
    "# preprocessing_processor = ScriptProcessor(\n",
    "#     image_uri=sagemaker.image_uris.retrieve(\"sklearn\", region=region, version=\"1.2-1\"),\n",
    "#     command=[\"python3\"],\n",
    "#     instance_type=\"ml.m5.xlarge\",\n",
    "#     instance_count=1,\n",
    "#     base_job_name=f\"{prefix}-preprocessing\",\n",
    "#     role=role,\n",
    "#     sagemaker_session=pipeline_session\n",
    "# )\n",
    "\n",
    "# preprocessing_step = ProcessingStep(\n",
    "#     name=\"PreprocessRenewalData\",\n",
    "#     processor=preprocessing_processor,\n",
    "#     inputs=[ProcessingInput(source=input_data_uri, destination=\"/opt/ml/processing/input\")],\n",
    "#     outputs=[\n",
    "#         ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "#         ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "#         ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\")\n",
    "#     ],\n",
    "#     code=\"preprocessing.py\"\n",
    "# )\n",
    "\n",
    "# # 2. Training Step using Native XGBoost Container\n",
    "# from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# xgb_estimator = XGBoost(\n",
    "#     entry_point=\"train.py\",\n",
    "#     framework_version=\"1.7-1\",  # Latest version with categorical support\n",
    "#     py_version=\"py3\",\n",
    "#     instance_type=\"ml.m5.xlarge\",\n",
    "#     instance_count=1,\n",
    "#     role=role,\n",
    "#     base_job_name=f\"{prefix}-training\",\n",
    "#     hyperparameters={\n",
    "#         \"num_round\": 500,\n",
    "#         \"max_depth\": 7,\n",
    "#         \"eta\": 0.01,\n",
    "#         \"subsample\": 0.8,\n",
    "#         \"colsample_bytree\": 0.8,\n",
    "#         \"min_child_weight\": 1,\n",
    "#         \"scale_pos_weight\": 0.324132467451242,\n",
    "#         \"objective\": \"binary:logistic\",\n",
    "#         \"eval_metric\": \"f1\",\n",
    "#         \"enable_categorical\": \"true\",  # String for XGBoost native container\n",
    "#         \"tree_method\": \"hist\"\n",
    "#     },\n",
    "#     output_path=model_uri,\n",
    "#     sagemaker_session=pipeline_session\n",
    "# )\n",
    "\n",
    "# train_step = TrainingStep(\n",
    "#     name=\"TrainRenewalModel\",\n",
    "#     estimator=xgb_estimator,\n",
    "#     inputs={\n",
    "#         \"train\": TrainingInput(\n",
    "#             s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "#             content_type=\"text/csv\"\n",
    "#         ),\n",
    "#         \"validation\": TrainingInput(\n",
    "#             s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "#             content_type=\"text/csv\"\n",
    "#         )\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # 3. Model Evaluation Step\n",
    "# evaluation_processor = ScriptProcessor(\n",
    "#     image_uri=sagemaker.image_uris.retrieve(\"sklearn\", region=region, version=\"1.2-1\"),\n",
    "#     command=[\"python3\"],\n",
    "#     instance_type=\"ml.m5.xlarge\",\n",
    "#     instance_count=1,\n",
    "#     base_job_name=f\"{prefix}-evaluation\",\n",
    "#     role=role,\n",
    "#     sagemaker_session=pipeline_session\n",
    "# )\n",
    "\n",
    "# eval_step = ProcessingStep(\n",
    "#     name=\"EvaluateRenewalModel\",\n",
    "#     processor=evaluation_processor,\n",
    "#     inputs=[\n",
    "#         ProcessingInput(\n",
    "#             source=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#             destination=\"/opt/ml/processing/model\"\n",
    "#         ),\n",
    "#         ProcessingInput(\n",
    "#             source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "#             destination=\"/opt/ml/processing/test\"\n",
    "#         )\n",
    "#     ],\n",
    "#     outputs=[\n",
    "#         ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")\n",
    "#     ],\n",
    "#     code=\"evaluate.py\"\n",
    "# )\n",
    "\n",
    "# # Property file for evaluation metrics\n",
    "# evaluation_report = PropertyFile(\n",
    "#     name=\"EvaluationReport\",\n",
    "#     output_name=\"evaluation\", \n",
    "#     path=\"evaluation.json\"\n",
    "# )\n",
    "# eval_step.add_property_files(evaluation_report)\n",
    "\n",
    "# # 4. Model Creation Step\n",
    "# model = Model(\n",
    "#     image_uri=sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.7-1\"),\n",
    "#     model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#     role=role,\n",
    "#     entry_point=\"inference.py\",\n",
    "#     sagemaker_session=pipeline_session\n",
    "# )\n",
    "\n",
    "# model_step = ModelStep(\n",
    "#     name=\"CreateRenewalModel\",\n",
    "#     step_args=model.create()\n",
    "# ) # for real-time inference\n",
    "\n",
    "# # 5. Batch Transform Step for Inference\n",
    "# transformer = Transformer(\n",
    "#     model_name=model_step.properties.ModelName,\n",
    "#     instance_type=\"ml.m5.xlarge\",\n",
    "#     instance_count=1,\n",
    "#     output_path=f\"{output_data_uri}/batch-inference\",\n",
    "#     accept=\"text/csv\",\n",
    "#     assemble_with=\"Line\",\n",
    "#     max_payload=6,\n",
    "#     sagemaker_session=pipeline_session\n",
    "# )\n",
    "\n",
    "# transform_step = TransformStep(\n",
    "#     name=\"BatchInferenceRenewal\",\n",
    "#     transformer=transformer,\n",
    "#     inputs=sagemaker.inputs.TransformInput(\n",
    "#         data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "#         content_type=\"text/csv\",\n",
    "#         split_type=\"Line\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 6. Model Registry Step with Condition\n",
    "# model_metrics = ModelMetrics(\n",
    "#     model_statistics=MetricsSource(\n",
    "#         s3_uri=f\"{eval_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']}/evaluation.json\",\n",
    "#         content_type=\"application/json\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# register_model_step = sagemaker.workflow.steps.RegisterModel(\n",
    "#     name=\"RegisterRenewalModel\",\n",
    "#     estimator=xgb_estimator,\n",
    "#     model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#     content_types=[\"text/csv\", \"application/json\"],\n",
    "#     response_types=[\"text/csv\", \"application/json\"],\n",
    "#     inference_instances=[\"ml.m5.xlarge\"],\n",
    "#     transform_instances=[\"ml.m5.xlarge\"],\n",
    "#     model_package_group_name=\"RenewalForecastModels\",\n",
    "#     approval_status=model_approval_status,\n",
    "#     model_metrics=model_metrics\n",
    "# )\n",
    "\n",
    "# # Only register model if F1 score >= 0.7\n",
    "# condition_step = ConditionStep(\n",
    "#     name=\"CheckModelPerformance\",\n",
    "#     conditions=[\n",
    "#         ConditionGreaterThanOrEqualTo(\n",
    "#             left=JsonGet(\n",
    "#                 step_name=eval_step.name,\n",
    "#                 property_file=evaluation_report,\n",
    "#                 json_path=\"binary_classification_metrics.f1\"\n",
    "#             ),\n",
    "#             right=0.70\n",
    "#         )\n",
    "#     ],\n",
    "#     if_steps=[model_step, transform_step, register_model_step],\n",
    "#     else_steps=[]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed14e3-97e5-4ea4-a853-56046747dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Pipeline\n",
    "# pipeline = Pipeline(\n",
    "#     name=\"RenewalForecastPipeline\",\n",
    "#     parameters=[model_approval_status],\n",
    "#     steps=[\n",
    "#         preprocessing_step,\n",
    "#         train_step, \n",
    "#         eval_step,\n",
    "#         condition_step\n",
    "#     ],\n",
    "#     sagemaker_session=pipeline_session\n",
    "# )\n",
    "\n",
    "# # Execute Pipeline\n",
    "# pipeline.upsert(role_arn=role)\n",
    "# execution = pipeline.start()\n",
    "\n",
    "# print(f\"Pipeline execution started: {execution.describe()['PipelineExecutionArn']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sagemaker_renforecast_env_2026)",
   "language": "python",
   "name": "sagemaker_renforecast_env_2026"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
